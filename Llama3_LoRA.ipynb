{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0665a80-6137-4a61-a3da-93bde606df04",
   "metadata": {},
   "source": [
    "Let's load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fce67d2-3703-4042-816c-7a13ba9eab3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "dataset_file = \"New_data.json\"\n",
    "\n",
    "with open(dataset_file, \"r\") as f:\n",
    "    alpaca = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9618cd92-acdd-471b-9521-d55c38af8040",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(list,\n",
       " [{'instruction': 'Generate search keywords for searching images/videos from the given paragraph. Consider relevant elements and keywords should capture the essence and context of the paragraph while aligning with the overall meaning of the input. Your output should be a list of python strings, and each string will correspond to a sentence in the input with a search keyword. All should have string values. The length of the list and the number of sentences in the given paragraph should be the same.',\n",
       "   'input': \" In a memorable opening match, Germany triumphed over Scotland, leaving the Scots in despair. The final score: Germany 5, Scotland 1. After Wirtz scored in the 10th minute, the game turned into a nightmare for Scotland.   Germany's victory was a history-making event, with Musiala, Havertz, Füllkrug, and Can scoring four additional goals. Scotland's defeat was sealed when Ryan Porteous was sent off, leaving Havertz to score from the penalty spot.   This match was unique in the history of the European Championships, featuring an own goal, a penalty goal, and a red card. Jamal Musiala, who scored Germany's second goal, was named UEFA's Player of the Match.   For the first time in Euro history, a coach, Julian Nagelsmann, fielded a player older than him, Manuel Neuer. This match marked Scotland's worst defeat since their friendly against the USA in 2012.  \",\n",
       "   'output': '[\\'Germany vs Scotland football match\\', \\'Musiala\\', \\'Havertz\\', \\'Füllkrug\\', \\'and Can scoring\\', \"Jamal Musiala UEFA\\'s Player of the Match\", \\'Julian Nagelsmann and Manuel Neuer\\']'},\n",
       "  {'instruction': 'Generate search keywords for searching images/videos from the given paragraph. Consider relevant elements and keywords should capture the essence and context of the paragraph while aligning with the overall meaning of the input. Your output should be a list of python strings, and each string will correspond to a sentence in the input with a search keyword. All should have string values. The length of the list and the number of sentences in the given paragraph should be the same.',\n",
       "   'input': \" Avadh Ojha shares his unfiltered thoughts on various topics including youth, politics, and the education system in a video presented by AJIO.   He discusses the challenges faced by today's youth in a rapidly changing world, emphasizing the importance of adaptability and resilience.   Ojha also delves into the complexities of politics, highlighting the need for transparency and accountability in governance.   He criticizes the current state of the education system, calling for reforms to better prepare students for the future.   Ojha's insightful commentary encourages viewers to critically analyze these issues and work towards creating positive change in society.   His perspective serves as a call to action for individuals to become more informed and actively involved in shaping a better future for themselves and future generations.  \",\n",
       "   'output': \"['Avadh Ojha speaking', 'challenges faced by youth', 'transparency in politics', 'education system reforms', 'positive change in society', 'shaping a better future']\"},\n",
       "  {'instruction': 'Generate search keywords for searching images/videos from the given paragraph. Consider relevant elements and keywords should capture the essence and context of the paragraph while aligning with the overall meaning of the input. Your output should be a list of python strings, and each string will correspond to a sentence in the input with a search keyword. All should have string values. The length of the list and the number of sentences in the given paragraph should be the same.',\n",
       "   'input': ' In the world of wealth and influence, these individuals stand out as titans of industry and innovation.   Each person on this list has not only amassed extraordinary wealth but has also shaped global economies, industries, and technological advancements.   Jeff Bezos, the visionary behind Amazon, continues to redefine e-commerce and cloud computing, fundamentally changing how we shop and compute.   Elon Musk, with his ventures Tesla and SpaceX, pushes boundaries in electric vehicles and space exploration, inspiring generations with his bold visions for the future.   Bernard Arnault, leading the luxury sector with brands like Louis Vuitton and Dior, epitomizes elegance and entrepreneurship on a global scale.   Bill Gates, co-founder of Microsoft and a leading philanthropist, remains dedicated to improving global health and education through his foundation.   Mark Zuckerberg, the driving force behind Facebook, connects billions worldwide and shapes social interaction in unprecedented ways.   These individuals not only symbolize wealth but also wield immense influence over technology, retail, luxury, and philanthropy, driving innovation and setting benchmarks for success in the modern era.  ',\n",
       "   'output': '[\"world\\'s top richest people\", \\'global economies and industries\\', \\'Jeff Bezos Amazon\\', \\'Elon Musk Tesla SpaceX\\', \\'Bernard Arnault Louis Vuitton Dior\\', \\'Bill Gates Microsoft\\', \\'Mark Zuckerberg Facebook\\', \\'influence over technology retail luxury philanthropy\\']'}],\n",
       " 9641)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(alpaca), alpaca[0:3], len(alpaca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9786466-4012-4cc4-8f9a-e673c74aa965",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33manishproshort\u001b[0m (\u001b[33mps-ml-team\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jupyter/FineTuning/wandb/run-20240625_072616-kh5n5tgz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ps-ml-team/data_ft_llama3LoRA/runs/kh5n5tgz' target=\"_blank\">classic-aardvark-12</a></strong> to <a href='https://wandb.ai/ps-ml-team/data_ft_llama3LoRA' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ps-ml-team/data_ft_llama3LoRA' target=\"_blank\">https://wandb.ai/ps-ml-team/data_ft_llama3LoRA</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ps-ml-team/data_ft_llama3LoRA/runs/kh5n5tgz' target=\"_blank\">https://wandb.ai/ps-ml-team/data_ft_llama3LoRA/runs/kh5n5tgz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='31.893 MB of 31.893 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">classic-aardvark-12</strong> at: <a href='https://wandb.ai/ps-ml-team/data_ft_llama3LoRA/runs/kh5n5tgz' target=\"_blank\">https://wandb.ai/ps-ml-team/data_ft_llama3LoRA/runs/kh5n5tgz</a><br/> View project at: <a href='https://wandb.ai/ps-ml-team/data_ft_llama3LoRA' target=\"_blank\">https://wandb.ai/ps-ml-team/data_ft_llama3LoRA</a><br/>Synced 5 W&B file(s), 1 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240625_072616-kh5n5tgz/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "# log to wandb\n",
    "with wandb.init(project=\"data_ft_llama3LoRA\"):\n",
    "    at = wandb.Artifact(\n",
    "        name=\"data\", \n",
    "        type=\"dataset\",\n",
    "        description=\"Using the data we finetune\",\n",
    "    )\n",
    "    at.add_file(dataset_file)\n",
    "\n",
    "    # log as a table\n",
    "    table = wandb.Table(columns=list(alpaca[0].keys()))\n",
    "    for row in alpaca:\n",
    "        table.add_data(*row.values())\n",
    "    wandb.log({\"data_table\": table})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5dfa1958-c58d-4b40-a7d9-5e0cc6d2abf5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "seed = 42\n",
    "\n",
    "random.seed(seed)\n",
    "random.shuffle(alpaca)  # this could also be a parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5492465c-c1b8-4f04-a154-36ce3bcb6610",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = alpaca[:-1000]\n",
    "eval_dataset = alpaca[-1000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fdbc0fd0-de6c-447d-abb9-3176c6ceeaf6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jupyter/FineTuning/wandb/run-20240625_072648-gtslv72n</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ps-ml-team/data_ft_llama3LoRA/runs/gtslv72n' target=\"_blank\">sunny-brook-13</a></strong> to <a href='https://wandb.ai/ps-ml-team/data_ft_llama3LoRA' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ps-ml-team/data_ft_llama3LoRA' target=\"_blank\">https://wandb.ai/ps-ml-team/data_ft_llama3LoRA</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ps-ml-team/data_ft_llama3LoRA/runs/gtslv72n' target=\"_blank\">https://wandb.ai/ps-ml-team/data_ft_llama3LoRA/runs/gtslv72n</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='31.894 MB of 31.894 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">sunny-brook-13</strong> at: <a href='https://wandb.ai/ps-ml-team/data_ft_llama3LoRA/runs/gtslv72n' target=\"_blank\">https://wandb.ai/ps-ml-team/data_ft_llama3LoRA/runs/gtslv72n</a><br/> View project at: <a href='https://wandb.ai/ps-ml-team/data_ft_llama3LoRA' target=\"_blank\">https://wandb.ai/ps-ml-team/data_ft_llama3LoRA</a><br/>Synced 5 W&B file(s), 2 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240625_072648-gtslv72n/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.DataFrame(train_dataset)\n",
    "eval_df = pd.DataFrame(eval_dataset)\n",
    "\n",
    "train_table = wandb.Table(dataframe=train_df)\n",
    "eval_table  = wandb.Table(dataframe=eval_df)\n",
    "\n",
    "train_df.to_json(\"data_train.jsonl\", orient='records', lines=True)\n",
    "eval_df.to_json(\"data_eval.jsonl\", orient='records', lines=True)\n",
    "\n",
    "with wandb.init(project=\"data_ft_llama3LoRA\", job_type=\"split_data\"):\n",
    "    at = wandb.Artifact(\n",
    "        name=\"data_splitted\", \n",
    "        type=\"dataset\",\n",
    "        description=\"Using the data we finetune\",\n",
    "    )\n",
    "    at.add_file(\"data_train.jsonl\")\n",
    "    at.add_file(\"data_eval.jsonl\")\n",
    "    wandb.log_artifact(at)\n",
    "    wandb.log({\"train_dataset\":train_table, \"eval_dataset\":eval_table})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b795343f-0356-4689-8bc6-9ac650716c8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prompt_input(row):\n",
    "    return (\"Below is an instruction that describes a task, paired with an input that provides further context. \"\n",
    "            \"Write a response that appropriately completes the request.\\n\\n\"\n",
    "            \"### Instruction:\\n{instruction}\\n\\n### Input:\\n{input}\\n\\n### Response:\\n\").format_map(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb58a76e-c50c-4431-8584-3a4597c2a0a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''import json\n",
    "from wandb import Api\n",
    "\n",
    "api = Api()\n",
    "artifact = api.artifact('data_ft/data_splitted', type='dataset')\n",
    "dataset_dir = artifact.download()'''\n",
    "\n",
    "def load_jsonl(file_path):\n",
    "    data = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            data.append(json.loads(line))\n",
    "    return data\n",
    "    \n",
    "train_dataset = load_jsonl(\"data_train.jsonl\")\n",
    "eval_dataset = load_jsonl(\"data_eval.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a78b4982-b683-41ee-bcec-8cfd22c2b4dc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'instruction': 'Generate search keywords for searching images/videos from the given paragraph. Consider relevant elements and keywords should capture the essence and context of the paragraph while aligning with the overall meaning of the input. Your output should be a list of python strings, and each string will correspond to a sentence in the input with a search keyword. All should have string values. The length of the list and the number of sentences in the given paragraph should be the same.', 'input': \" The small village of Eldoria lay nestled in a lush valley, encircled by the towering peaks of the Azure Mountains.   Among the villagers was a young girl named Elara. She was known for her vibrant spirit and insatiable curiosity, always asking questions about the world beyond their serene village.   Her grandmother, Liora, was the village's wise woman, revered for her knowledge of ancient spells and forgotten lore. Elara spent countless hours in her grandmother’s cozy cottage, listening to tales of grand adventures and mythical creatures.   One crisp autumn morning, as Elara was gathering herbs in the forest, she stumbled upon an old, weathered map tucked inside a hollow tree.   “Grandmother, look what I found!” Elara exclaimed, spreading the map out on the wooden table.   Liora's eyes widened as she studied the map. “This is the Lost Path of the Phoenix,” she whispered. “It is said to lead to the Sacred Springs, where the Phoenix of Renewal resides. Legend has it that the Phoenix grants a single wish to those who find the springs.”  \", 'output': \"['Small Village Eldoria Azure Mountains', 'Curious young girl village', 'Grandmother telling stories cottage', 'Girl finding old map in forest', 'girl showing map to grandmother', 'Phoenix map leading to Sacred Springs']\"}\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41703ce9-a22d-4245-9f6c-a424afd9ef11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_prompts = [prompt_input(row) for row in train_dataset]\n",
    "eval_prompts = [prompt_input(row) for row in eval_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a4c16a0-989b-4e17-bc07-e1cc95971813",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Generate search keywords for searching images/videos from the given paragraph. Consider relevant elements and keywords should capture the essence and context of the paragraph while aligning with the overall meaning of the input. Your output should be a list of python strings, and each string will correspond to a sentence in the input with a search keyword. All should have string values. The length of the list and the number of sentences in the given paragraph should be the same.\n",
      "\n",
      "### Input:\n",
      " The small village of Eldoria lay nestled in a lush valley, encircled by the towering peaks of the Azure Mountains.   Among the villagers was a young girl named Elara. She was known for her vibrant spirit and insatiable curiosity, always asking questions about the world beyond their serene village.   Her grandmother, Liora, was the village's wise woman, revered for her knowledge of ancient spells and forgotten lore. Elara spent countless hours in her grandmother’s cozy cottage, listening to tales of grand adventures and mythical creatures.   One crisp autumn morning, as Elara was gathering herbs in the forest, she stumbled upon an old, weathered map tucked inside a hollow tree.   “Grandmother, look what I found!” Elara exclaimed, spreading the map out on the wooden table.   Liora's eyes widened as she studied the map. “This is the Lost Path of the Phoenix,” she whispered. “It is said to lead to the Sacred Springs, where the Phoenix of Renewal resides. Legend has it that the Phoenix grants a single wish to those who find the springs.”  \n",
      "\n",
      "### Response:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(train_prompts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06177a5c-84ff-4be3-8d2b-6a483c8ae5e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pad_eos(ds):\n",
    "    EOS_TOKEN = \"</s>\"\n",
    "    return [f\"{row['output']}{EOS_TOKEN}\" for row in ds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc5b21e8-3d5b-4964-be7b-faff5038f7f3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['Small Village Eldoria Azure Mountains', 'Curious young girl village', 'Grandmother telling stories cottage', 'Girl finding old map in forest', 'girl showing map to grandmother', 'Phoenix map leading to Sacred Springs']</s>\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_outputs = pad_eos(train_dataset)\n",
    "eval_outputs = pad_eos(eval_dataset)\n",
    "train_outputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cdea7bc4-1ec3-451e-ab00-549aa2056800",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = [{\"prompt\":s, \"output\":t, \"example\": s + t} for s, t in zip(train_prompts, train_outputs)]\n",
    "eval_dataset = [{\"prompt\":s, \"output\":t, \"example\": s + t} for s, t in zip(eval_prompts, eval_outputs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e923b9bb-ced2-44f9-88f3-1c7690dde802",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Generate search keywords for searching images/videos from the given paragraph. Consider relevant elements and keywords should capture the essence and context of the paragraph while aligning with the overall meaning of the input. Your output should be a list of python strings, and each string will correspond to a sentence in the input with a search keyword. All should have string values. The length of the list and the number of sentences in the given paragraph should be the same.\n",
      "\n",
      "### Input:\n",
      " The small village of Eldoria lay nestled in a lush valley, encircled by the towering peaks of the Azure Mountains.   Among the villagers was a young girl named Elara. She was known for her vibrant spirit and insatiable curiosity, always asking questions about the world beyond their serene village.   Her grandmother, Liora, was the village's wise woman, revered for her knowledge of ancient spells and forgotten lore. Elara spent countless hours in her grandmother’s cozy cottage, listening to tales of grand adventures and mythical creatures.   One crisp autumn morning, as Elara was gathering herbs in the forest, she stumbled upon an old, weathered map tucked inside a hollow tree.   “Grandmother, look what I found!” Elara exclaimed, spreading the map out on the wooden table.   Liora's eyes widened as she studied the map. “This is the Lost Path of the Phoenix,” she whispered. “It is said to lead to the Sacred Springs, where the Phoenix of Renewal resides. Legend has it that the Phoenix grants a single wish to those who find the springs.”  \n",
      "\n",
      "### Response:\n",
      "['Small Village Eldoria Azure Mountains', 'Curious young girl village', 'Grandmother telling stories cottage', 'Girl finding old map in forest', 'girl showing map to grandmother', 'Phoenix map leading to Sacred Springs']</s>\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset[0][\"example\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "720c707b-3bce-4164-b8c1-3c3122200c39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4162aec8-f2ba-45db-9633-817b416d4e57",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "model_id = 'meta-llama/Meta-Llama-3-8B-Instruct'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58586813-7918-4578-9583-df14c5a6a6ad",
   "metadata": {},
   "source": [
    "### Packing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d316d169-4292-41aa-a42d-cd49620a881c",
   "metadata": {},
   "source": [
    "We will pack multiple short examples into a longer chunk, so we can train more efficiently!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6df54e-f6bc-4e56-aec2-014a19fc654c",
   "metadata": {},
   "source": [
    "The main idea here is that the instruction/output samples are short, so let's concatenate a bunch of them together separated by the `EOS` token. We can also pre-tokenize and pre-pack the dataset and make everything faster!  If we define a `max_seq_len = 1024` the code to pack would look something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a537da60-db69-42a7-8c66-0ea3756c2847",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_sequence_len = 1024\n",
    "\n",
    "def pack(dataset, max_seq_len=max_sequence_len):\n",
    "    tkds_ids = tokenizer([s[\"example\"] for s in dataset])[\"input_ids\"]\n",
    "    \n",
    "    all_token_ids = []\n",
    "    for tokenized_input in tkds_ids:\n",
    "        all_token_ids.extend(tokenized_input)# + [tokenizer.eos_token_id])\n",
    "    \n",
    "    print(f\"Total number of tokens: {len(all_token_ids)}\")\n",
    "    packed_ds = []\n",
    "    for i in range(0, len(all_token_ids), max_seq_len+1):\n",
    "        input_ids = all_token_ids[i : i + max_seq_len+1]\n",
    "        if len(input_ids) == (max_seq_len+1):\n",
    "            packed_ds.append({\"input_ids\": input_ids[:-1], \"labels\": input_ids[1:]})  # this shift is not needed if using the model.loss\n",
    "    return packed_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9c78b4e9-2c7f-4aa1-b738-be04bc55b06b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tokens: 3260445\n",
      "Total number of tokens: 379440\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3180"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds_packed = pack(train_dataset)\n",
    "eval_ds_packed = pack(eval_dataset)\n",
    "len(train_ds_packed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43713b3-9f65-42a6-8338-ab0601e5f476",
   "metadata": {},
   "source": [
    "### DataLoader\n",
    "As we are training for completion, the labels (or targets) will be the inputs shifted by one. We are going to train with regular Cross Entropy and predict the next token on this packed dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f342873a-29a3-4ed1-8b59-9e7f7f2a4c1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from transformers import default_data_collator\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "batch_size = 4  # I have an A100 GPU with 40GB of RAM 😎\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_ds_packed,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=default_data_collator, # we don't need any special collator 😎\n",
    ")\n",
    "\n",
    "eval_dataloader = DataLoader(\n",
    "    eval_ds_packed,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=default_data_collator,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2ccaf4-dfa1-4daa-9a6f-244c8cda7818",
   "metadata": {},
   "source": [
    "It is always a good idea to check how does a batch looks like, you can quickly do this by sampling from the DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ffced7ec-bd1b-42b0-be64-04f3fae5df84",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[128000,  39314,    374,  ...,   3862,   6634, 101565],\n",
       "         [  5320, 107633,     11,  ...,  50228,    106, 100278],\n",
       "         [   100,  87648,  28025,  ...,    223,  11372,    100],\n",
       "         [   223,  36278,    237,  ...,   1988,    430,   5825]]),\n",
       " 'labels': tensor([[ 39314,    374,    459,  ...,   6634, 101565,  14115],\n",
       "         [107633,     11,    841,  ...,    106, 100278,  36278],\n",
       "         [ 87648,  28025,    222,  ...,  11372,    100,  28025],\n",
       "         [ 36278,    237,  11372,  ...,    430,   5825,   4726]])}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = next(iter(train_dataloader))\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d15d30-58d2-465d-a9f4-be0eef2ea06b",
   "metadata": {},
   "source": [
    "We can alos decode the batch just to be super sure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "28e18ad2-c141-4902-a5a4-24a1e743be35",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nGenerate search keywords for searching images/videos from'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(b[\"input_ids\"][0])[:250]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f0a46e93-7ec2-4365-8e50-be7bef873436",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nGenerate search keywords for searching images/videos from the given paragr'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(b[\"labels\"][0])[:250]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb99a7dc-0654-4985-ac3f-60ecdc6f6558",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9757e458-14fd-4dd3-861f-efad04dce787",
   "metadata": {},
   "source": [
    "I like storing all my hyperparameters into a `SimpleNamespace`, it's like a dict but with .dot attribute access. Then I can access my batch size by doing config.batch_size instead of config[\"batch_size\"]. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6925a62e-d85e-4c86-8867-bee3a180fc08",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from types import SimpleNamespace\n",
    "\n",
    "gradient_accumulation_steps = 2\n",
    "\n",
    "config = SimpleNamespace(\n",
    "    model_id='meta-llama/Meta-Llama-3-8B-Instruct',\n",
    "    dataset_name=\"data\",\n",
    "    precision=\"bf16\",  # faster and better than fp16, requires new GPUs\n",
    "    lr=2e-5,\n",
    "    n_eval_samples=10, # How many samples to generate on validation\n",
    "    max_seq_len=max_sequence_len, # Lenght of the sequences to pack\n",
    "    epochs=3,  # we do 3 pasess over the dataset.\n",
    "    gradient_accumulation_steps=gradient_accumulation_steps,  # evey how many iterations we update the gradients, simulates larger batch sizes\n",
    "    batch_size=batch_size,  # what my GPU can handle, depends on how many layers are we training  \n",
    "    log_model=False,  # upload the model to W&B?\n",
    "    gradient_checkpointing = True,  # saves even more memory\n",
    "    freeze_embed = True,  # why train this? let's keep them frozen ❄️\n",
    "    seed=seed,\n",
    ")\n",
    "\n",
    "config.total_train_steps = config.epochs * len(train_dataloader) // config.gradient_accumulation_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0a7166a6-8e88-4f0d-bc0e-70aac292c645",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We will train for 1192 steps and evaluate every epoch\n"
     ]
    }
   ],
   "source": [
    "print(f\"We will train for {config.total_train_steps} steps and evaluate every epoch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bcd0229-5e4c-4bb5-827b-309bdbb351df",
   "metadata": {},
   "source": [
    "We first get a pretrained model with some configuration parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5b181225",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6aca89a74e70438cab6dcc65e32122a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "from transformers import BitsAndBytesConfig\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from peft import LoraConfig, get_peft_model\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "            load_in_4bit=True,\n",
    "            bnb_4bit_use_double_quant=True,\n",
    "            bnb_4bit_quant_type=\"nf4\",\n",
    "            bnb_4bit_compute_dtype=torch.bfloat16,)\n",
    "# Load the model and tokenizer\n",
    "model_id = 'meta-llama/Meta-Llama-3-8B-Instruct'\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, device_map=0,trust_remote_code=True,\n",
    "    low_cpu_mem_usage=True,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    use_cache=False)\n",
    "\n",
    "# Configure LoRA\n",
    "lora_config = LoraConfig(\n",
    "    r=128,\n",
    "    lora_alpha=64,\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    target_modules= ['k_proj', 'q_proj', 'v_proj', 'o_proj', \"gate_proj\", \"down_proj\", \"up_proj\"]\n",
    ")\n",
    "\n",
    "# Wrap the model with LoRA\n",
    "model = get_peft_model(model, lora_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fc6c3959-854c-409e-9037-b5c87a6adce5",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total params: 8365.81M, Trainable: 335.54M\n"
     ]
    }
   ],
   "source": [
    "def param_count(m):\n",
    "    params = sum([p.numel() for p in m.parameters()])/1_000_000\n",
    "    trainable_params = sum([p.numel() for p in m.parameters() if p.requires_grad])/1_000_000\n",
    "    print(f\"Total params: {params:.2f}M, Trainable: {trainable_params:.2f}M\")\n",
    "    return params, trainable_params\n",
    "\n",
    "params, trainable_params = param_count(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc92663c-95a4-4ecc-a9af-7a68d9648271",
   "metadata": {},
   "source": [
    "### Optimizer\n",
    "\n",
    "We setup the standard optimization stuff..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5374c44d-517b-42a0-ade6-297c0a5d18b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import get_cosine_schedule_with_warmup\n",
    "\n",
    "optim = torch.optim.Adam(model.parameters(), lr=config.lr, betas=(0.9,0.99), eps=1e-5)\n",
    "scheduler = get_cosine_schedule_with_warmup(\n",
    "    optim,\n",
    "    num_training_steps=config.total_train_steps,\n",
    "    num_warmup_steps=config.total_train_steps // 10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5efdd402-c851-47a5-9134-5b47b7d118e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def loss_fn(x, y):\n",
    "    \"A Flat CrossEntropy\" \n",
    "    return torch.nn.functional.cross_entropy(x.view(-1, x.shape[-1]), y.view(-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24440392-9837-4cbb-873a-372f9f5aca20",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Testing during training\n",
    "\n",
    "We are almost there, let's create a simple function to sample from the model now and then, to visualy see what the models is outputting!\n",
    "Let's wrap the model.generate method for simplicity. You can grab the defaults sampling parameters from the GenerationConfig and passing the corresponding model_id. This will grab you the defaults for parameters like temperature, top p, etc...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e0a92fe7-3f9e-43e6-80b0-adbbd8b480ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from types import SimpleNamespace\n",
    "from transformers import GenerationConfig\n",
    "\n",
    "gen_config = GenerationConfig.from_pretrained(config.model_id)\n",
    "test_config = SimpleNamespace(\n",
    "    max_new_tokens=256,\n",
    "    gen_config=gen_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9ec41718-52c6-4335-a534-2790d03ba069",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate(prompt, max_new_tokens=test_config.max_new_tokens, gen_config=gen_config):\n",
    "    tokenized_prompt = tokenizer(prompt, return_tensors='pt')['input_ids'].cuda()\n",
    "    with torch.inference_mode():\n",
    "        output = model.generate(tokenized_prompt, \n",
    "                            max_new_tokens=max_new_tokens, \n",
    "                            generation_config=gen_config,\n",
    "                            pad_token_id=tokenizer.eos_token_id)\n",
    "    return tokenizer.decode(output[0][len(tokenized_prompt[0]):], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44601edc-db5b-40ea-bb74-9591ea4e7e50",
   "metadata": {},
   "source": [
    "LoL 🤷"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b4e39c49-ccb1-4fe6-aa30-988ea5583b99",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Generate search keywords for searching images/videos from the given paragraph. Consider relevant elements and keywords should capture the essence and context of the paragraph while aligning with the overall meaning of the input. Your output should be a list of python strings, and each string will correspond to a sentence in the input with a search keyword. All should have string values. The length of the list and the number of sentences in the given paragraph should be the same.\n",
      "\n",
      "### Input:\n",
      " The video '7 Days Stranded On An Island' on YouTube shows a group of people surviving in a remote location for a week.   They faced various challenges such as finding food and shelter, and had to rely on their survival skills.   The group managed to build a fire, catch fish for food, and find sources of fresh water.   They also showed how important teamwork and cooperation are in such situations, as they worked together to overcome obstacles.   The video highlights the importance of preparation and resourcefulness in surviving in the wilderness.   Overall, the experience tested their resilience and determination to survive in a challenging environment.   Watching their journey provides valuable insights into the skills and mindset needed to endure such a situation.  \n",
      "\n",
      "### Response:\n",
      "Here is the list of search keywords for the given paragraph:\n",
      "\n",
      "['7 Days Stranded On An Island','survival skills', 'finding food and shelter', 'building a fire', 'catching fish', 'fresh water', 'teamwork', 'cooperation', 'preparation','resourcefulness', 'wilderness survival','resilience', 'determination', 'enduring a challenging environment','survival journey', 'valuable insights']\n",
      "\n",
      "Each sentence in the input has been paired with a search keyword that captures the essence and context of the sentence, while aligning with the overall meaning of the paragraph.\n"
     ]
    }
   ],
   "source": [
    "prompt = eval_dataset[16][\"prompt\"]\n",
    "print(prompt + generate(prompt, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bac25c48-cb18-4560-b05c-1748e7d1adf5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import wandb\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def prompt_table(examples, log=False, table_name=\"predictions\"):\n",
    "    table = wandb.Table(columns=[\"prompt\", \"generation\", \"concat\", \"output\", \"max_new_tokens\", \"temperature\", \"top_p\"])\n",
    "    for example in tqdm(examples, leave=False):\n",
    "        prompt, gpt4_output = example[\"prompt\"], example[\"output\"]\n",
    "        out = generate(prompt, test_config.max_new_tokens, test_config.gen_config)\n",
    "        table.add_data(prompt, out, prompt+out, gpt4_output, test_config.max_new_tokens, test_config.gen_config.temperature, test_config.gen_config.top_p)\n",
    "    if log:\n",
    "        wandb.log({table_name:table})\n",
    "    return table\n",
    "\n",
    "def to_gpu(tensor_dict):\n",
    "    return {k: v.to('cuda') for k, v in tensor_dict.items()}\n",
    "\n",
    "class Accuracy:\n",
    "    \"A simple Accuracy function compatible with HF models\"\n",
    "    def __init__(self):\n",
    "        self.count = 0\n",
    "        self.tp = 0.\n",
    "    def update(self, logits, labels):\n",
    "        logits, labels = logits.argmax(dim=-1).view(-1).cpu(), labels.view(-1).cpu()\n",
    "        tp = (logits == labels).sum()\n",
    "        self.count += len(logits)\n",
    "        self.tp += tp\n",
    "        return tp / len(logits)\n",
    "    def compute(self):\n",
    "        return self.tp / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "53aeac2a-1eb6-48cc-bc97-de038a80530c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "\n",
    "# Initialize the ROUGE scorer for bigrams (ROUGE-2)\n",
    "scorer = rouge_scorer.RougeScorer(['rouge2'], use_stemmer=True)\n",
    "\n",
    "def compute_rouge2(predictions, references):\n",
    "    rouge2_scores = []\n",
    "    for pred, ref in zip(predictions, references):\n",
    "        score = scorer.score(ref, pred)['rouge2'].fmeasure\n",
    "        rouge2_scores.append(score)\n",
    "    return sum(rouge2_scores) / len(rouge2_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52fbc09-5d65-4265-abce-adda01d85584",
   "metadata": {},
   "source": [
    "You can also quickly add validation if you feel so, the table can be also created at this step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6891b2c0-f22e-4647-9ac2-e07a994f3e96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def validate():\n",
    "    model.eval()\n",
    "    eval_acc = Accuracy()\n",
    "    loss, total_steps = 0., 0\n",
    "    for step, batch in enumerate(pbar:=tqdm(eval_dataloader, leave=False)):\n",
    "        pbar.set_description(f\"doing validation\")\n",
    "        batch = to_gpu(batch)\n",
    "        total_steps += 1\n",
    "        with torch.amp.autocast(\"cuda\", dtype=torch.bfloat16):\n",
    "            out = model(**batch)\n",
    "            loss += loss_fn(out.logits, batch[\"labels\"])  # you could use out.loss and not shift the dataset\n",
    "        predictions = tokenizer.batch_decode(out.logits.argmax(dim=-1), skip_special_tokens=True)\n",
    "        references = tokenizer.batch_decode(batch[\"labels\"], skip_special_tokens=True)\n",
    "        # Compute ROUGE-2 score\n",
    "        rouge2_score = compute_rouge2(predictions, references)\n",
    "    # we log results at the end\n",
    "    wandb.log({\"eval/loss\": loss.item() / total_steps,\n",
    "               \"eval/rouge2_score\": rouge2_score})\n",
    "    prompt_table(eval_dataset[:config.n_eval_samples], log=True)\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93834c0b-15e1-4e43-8535-dbb9f36af29d",
   "metadata": {},
   "source": [
    "Let's define a loop that compute evaluation and logs a Table with model predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e90177c-0c5a-48e7-9a39-2b9e67794814",
   "metadata": {},
   "source": [
    "## The actual Loop\n",
    "It's actually nothing fancy, and very short! It has:\n",
    "- Gradient accumulation and gradient scaling\n",
    "- sampling and model checkpoint saving (this trains very fast, no need to save multiple checkpoints)\n",
    "- We compute token accuracy, better metric than loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe75078a-5d35-46bc-8f33-0e3adf52d072",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jupyter/FineTuning/wandb/run-20240625_073002-fubxw1lj</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ps-ml-team/data_ft_llama3LoRA/runs/fubxw1lj' target=\"_blank\">dauntless-jazz-14</a></strong> to <a href='https://wandb.ai/ps-ml-team/data_ft_llama3LoRA' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ps-ml-team/data_ft_llama3LoRA' target=\"_blank\">https://wandb.ai/ps-ml-team/data_ft_llama3LoRA</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ps-ml-team/data_ft_llama3LoRA/runs/fubxw1lj' target=\"_blank\">https://wandb.ai/ps-ml-team/data_ft_llama3LoRA/runs/fubxw1lj</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "666d07ee59a342fcba924011b49d93c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4320e7c26a6f4182ad60951113ab99f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/795 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.init(project=\"data_ft_llama3LoRA\", # the project I am working on\n",
    "           tags=[\"baseline\",\"8b\"],\n",
    "           job_type=\"train\",\n",
    "           config=config) # the Hyperparameters I want to keep track of\n",
    "\n",
    "# Training\n",
    "\n",
    "acc = Accuracy()\n",
    "model.train()\n",
    "train_step = 0\n",
    "for epoch in tqdm(range(config.epochs)):\n",
    "    for step, batch in enumerate(tqdm(train_dataloader)):\n",
    "        batch = to_gpu(batch)\n",
    "        with torch.amp.autocast(\"cuda\", dtype=torch.bfloat16):\n",
    "            out = model(**batch)\n",
    "            loss = loss_fn(out.logits, batch[\"labels\"]) / config.gradient_accumulation_steps  # you could use out.loss and not shift the dataset  \n",
    "            loss.backward()\n",
    "        if step%config.gradient_accumulation_steps == 0:\n",
    "            # Convert logits to predictions and references to text\n",
    "            predictions = tokenizer.batch_decode(out.logits.argmax(dim=-1), skip_special_tokens=True)\n",
    "            references = tokenizer.batch_decode(batch[\"labels\"], skip_special_tokens=True)\n",
    "            \n",
    "            # Compute ROUGE-2 score\n",
    "            rouge2_score = compute_rouge2(predictions, references)\n",
    "            # we can log the metrics to W&B\n",
    "            wandb.log({\"train/loss\": loss.item() * config.gradient_accumulation_steps,\n",
    "                       \"train/rouge2_score\": rouge2_score,\n",
    "                       \"train/learning_rate\": scheduler.get_last_lr()[0],\n",
    "                       \"train/global_step\": train_step})\n",
    "            optim.step()\n",
    "            scheduler.step()\n",
    "            optim.zero_grad(set_to_none=True)\n",
    "            train_step += 1\n",
    "    validate()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4099bc28-e695-46a6-994c-b612f7811937",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# we save the model checkpoint at the end\n",
    "#save_model(model, model_name=config.model_id.replace(\"/\", \"_\"), models_folder=\"models/\", log=config.log_model)\n",
    "    \n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec95b95-3e81-4a40-8eea-34048c992ba9",
   "metadata": {},
   "source": [
    "This trains in around 60 minutes on an A100. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a936e007-47fa-400f-873c-5e038bd685c5",
   "metadata": {},
   "source": [
    "## Full Eval Dataset evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399fafb9-b41f-401b-a1c4-37e1ede2e639",
   "metadata": {},
   "source": [
    "Let's log a table with model predictions on the eval_dataset (or at least the 250 first samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b89717a-ac70-43e8-9b7c-edd8d2c54cdc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with wandb.init(project=\"data_ft_llama3LoRA\", # the project I am working on\n",
    "           job_type=\"eval\",\n",
    "           config=config): # the Hyperparameters I want to keep track of\n",
    "    model.eval();\n",
    "    prompt_table(eval_dataset[:250], log=True, table_name=\"eval_predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c93a50-049f-4c69-a392-7608be93254a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.save_pretrained(\"fine_tuned/data_new_ft_llama3QLoRA\")\n",
    "tokenizer.save_pretrained('fine_tuned/data_new_ft_llama3QLoRA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669b4162-5192-4131-879b-0fe2d70066a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python llama.cpp/convert-hf-to-gguf.py fine_tuned/data_new_ft_llama3QLoRA_full --outfile \"llama3Q-ft.gguf\" --outtype f16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055fca99-638a-477a-8f15-978aa11dc46c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!./llama.cpp/ggml-quants.h \"phi3-ft.gguf\" \"phi3-ft-Q5_K_M.gguf\" \"q5_k_m\""
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m121",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m121"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
