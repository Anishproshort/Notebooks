{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af4bd82b-4435-46c7-886d-3ff72681673a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3a1e7a28ca64a43bba35c918a940c20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# Load the model\n",
    "model = AutoModelForCausalLM.from_pretrained(\"microsoft/Phi-3-mini-128k-instruct\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-3-mini-128k-instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c927f8a-ad3b-4887-b17b-f35c4a954a01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_text = '''Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "Generate search keywords for searching images/videos from the given paragraph. Consider relevant elements andkeywords should capture the essence and context of the paragraph while aligning with the overall meaning of the input. In total generate 2 - 3 main keywords.Your output should be a list of python strings, and each string will correspond to a sentence in the input with a search keyword. All should have string values. Also ensure that the output is of the same length as the number of sentences.\n",
    "\n",
    "\n",
    "### Input:\n",
    "Omen, the master of shadows in Valorant, is well known for striking from unexpected places and creating a sense of chaos among his enemies.\n",
    "One of his most perplexing abilities is 'Shrouded Step', which allows him to disappear and reappear, leaving his enemies bewildered.\n",
    "'Paranoia', another of Omen's abilities, blinds his foes, inciting fear and confusion in them.\n",
    "With 'From the Shadows', Omen can teleport to any location on the map, providing his team with a significant strategic advantage.\n",
    "As we conclude our spotlight on Omen, remember, when you face him, be prepared for the darkness. This is Omen, the deathly figure from the shadows.\n",
    "\n",
    "### Response:'''\n",
    "inputs = tokenizer(input_text, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "840f9d67-a37e-4048-8070-baa16ded6048",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are not running the flash-attention implementation, expect numerical differences.\n"
     ]
    }
   ],
   "source": [
    "outputs = model.generate(\n",
    "    inputs.input_ids, \n",
    "    max_new_tokens=40,  # Ensure the output is short\n",
    "    temperature=0.7,  # Adjust temperature to control randomness\n",
    "    top_p=0.9,  # Use nucleus sampling for more coherent outputs\n",
    "    num_beams=5,  # Use beam search to enhance the quality of the output\n",
    "    num_return_sequences=1,  # Generate only one sequence\n",
    "    no_repeat_ngram_size=2,  # Prevent repetition\n",
    "    do_sample=True  # Enable sampling\n",
    ")\n",
    "generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c1b9ad5-83d9-4063-96f1-347257850906",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated output: Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Generate search keywords for searching images/videos from the given paragraph. Consider relevant elements andkeywords should capture the essence and context of the paragraph while aligning with the overall meaning of the input. In total generate 2 - 3 main keywords.Your output should be a list of python strings, and each string will correspond to a sentence in the input with a search keyword. All should have string values. Also ensure that the output is of the same length as the number of sentences.\n",
      "\n",
      "\n",
      "### Input:\n",
      "Jon Rahm, the 2021 US Open champion, had to withdraw from the upcoming major at Pinehurst No 2 due to a foot infection.\n",
      "This will be his first missed major since 2016, a significant setback for the former world No 1.\n",
      "The decision came after Rahm consulted with doctors and his team, prioritizing his long-term health.\n",
      "The golfer's foot infection forced him to withdraw from a previous event in Houston and wear mismatched shoes at a press conference.\n",
      "These developments have left fans and pundits speculating about the impact on the tournament and Rahm's future in the sport.\n",
      "Despite this setback, golf enthusiasts can still catch all the action of the US Open live on Sky Sports Golf.\n",
      "It remains to be seen how Rahm's recovery progresses and when he will return to competitive play.\n",
      "\n",
      "### Response: ```python\n",
      "[\"Rahm\", \"US Open Champion\", \n",
      " \"withdrawal from major tournament\",\n",
      "  \"golfer health speculation\",  \n",
      "   \"live action US\n"
     ]
    }
   ],
   "source": [
    "print(\"Generated output:\", generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7fab6af1-3da4-410b-a5f4-0d4ecef4d28a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "from peft import PeftConfig, PeftModel\n",
    "adapter_model_name = \"fine_tuned/data_new_ft_phi3LoRA\"\n",
    "model = PeftModel.from_pretrained(model, adapter_model_name)\n",
    "\n",
    "model = model.merge_and_unload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4ab2b01-ddb1-49d1-8d1e-6a6fb26b1c43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "outputs = model.generate(\n",
    "    inputs.input_ids, \n",
    "    max_new_tokens=40,  # Ensure the output is short\n",
    "    temperature=0.7,  # Adjust temperature to control randomness\n",
    "    top_p=0.9,  # Use nucleus sampling for more coherent outputs\n",
    "    num_beams=5,  # Use beam search to enhance the quality of the output\n",
    "    num_return_sequences=1,  # Generate only one sequence\n",
    "    no_repeat_ngram_size=2,  # Prevent repetition\n",
    "    do_sample=True  # Enable sampling\n",
    ")\n",
    "generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad55871a-bbd1-43d4-b395-3e3991b6013c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated output: Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Generate search keywords for searching images/videos from the given paragraph. Consider relevant elements andkeywords should capture the essence and context of the paragraph while aligning with the overall meaning of the input. In total generate 2 - 3 main keywords.Your output should be a list of python strings, and each string will correspond to a sentence in the input with a search keyword. All should have string values. Also ensure that the output is of the same length as the number of sentences.\n",
      "\n",
      "\n",
      "### Input:\n",
      "Jon Rahm, the 2021 US Open champion, had to withdraw from the upcoming major at Pinehurst No 2 due to a foot infection.\n",
      "This will be his first missed major since 2016, a significant setback for the former world No 1.\n",
      "The decision came after Rahm consulted with doctors and his team, prioritizing his long-term health.\n",
      "The golfer's foot infection forced him to withdraw from a previous event in Houston and wear mismatched shoes at a press conference.\n",
      "These developments have left fans and pundits speculating about the impact on the tournament and Rahm's future in the sport.\n",
      "Despite this setback, golf enthusiasts can still catch all the action of the US Open live on Sky Sports Golf.\n",
      "It remains to be seen how Rahm's recovery progresses and when he will return to competitive play.\n",
      "\n",
      "### Response:  \n",
      "['US Open championship', 'Rahm withdrawing from major', \n",
      "'Foot injury and medical consultation']</s> Here is a set of instructions that captures key aspects of\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Generated output:\", generated_text)\n"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m121",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m121"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
